{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pyaspeller import YandexSpeller\n",
    "from nltk import sent_tokenize\n",
    "from transliterate import translit\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from rnnmorph.predictor import RNNMorphPredictor\n",
    "from ufal.udpipe import Model, Pipeline, ProcessingError\n",
    "\n",
    "sys.path.append('../src')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "\n",
    "from encode import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>hr_level_0</th>\n",
       "      <th>hr_level_1</th>\n",
       "      <th>hr_level_2</th>\n",
       "      <th>hr_level_3</th>\n",
       "      <th>hr_level_4</th>\n",
       "      <th>publication</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>snippet</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Финмаркет</td>\n",
       "      <td>2018-03-29T14:13:00</td>\n",
       "      <td>В этом году на льготные автокредиты и лизинг б...</td>\n",
       "      <td>FINMARKET.RU - Премьер России Дмитрий Медведев...</td>\n",
       "      <td>В этом году на льготные автокредиты и лизинг б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ТАСС</td>\n",
       "      <td>2018-03-29T14:16:00</td>\n",
       "      <td>Медведев: около 50 тыс. машин продадут в 2018 ...</td>\n",
       "      <td>Около 50 тыс. автомашин будет продано в текуще...</td>\n",
       "      <td>Около 50 тыс. автомашин будет продано в текуще...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Российская газета</td>\n",
       "      <td>2018-03-29T14:30:00</td>\n",
       "      <td>Кабмин выделит 7 миллиардов рублей на льготное...</td>\n",
       "      <td>Правительство выделяет 7 миллиардов рублей на ...</td>\n",
       "      <td>Названы ставки по ипотеке и автокредитам в 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Телеканал 360°</td>\n",
       "      <td>2018-03-29T14:43:00</td>\n",
       "      <td>Правительство РФ выделит порядка 7 млрд на льг...</td>\n",
       "      <td>Из указанной суммы около семи миллиардов напра...</td>\n",
       "      <td>Правительством России предусмотрено свыше 12 м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Интерфакс</td>\n",
       "      <td>2018-03-29T15:38:00</td>\n",
       "      <td>Правительство выделит в 2018 г. около 7 млрд р...</td>\n",
       "      <td>Правительство РФ выделит в 2018 году около 7 м...</td>\n",
       "      <td>Правительство РФ выделит в 2018 году около 7 м...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  hr_level_0  hr_level_1  hr_level_2  hr_level_3  hr_level_4  \\\n",
       "0   0           0           0         NaN       152.0         NaN   \n",
       "1   1           0           0         NaN       152.0         NaN   \n",
       "2   2           0           0         NaN       152.0         NaN   \n",
       "3   3           0           0         NaN       152.0         NaN   \n",
       "4   4           0           0         NaN       152.0         NaN   \n",
       "\n",
       "         publication                 time  \\\n",
       "0          Финмаркет  2018-03-29T14:13:00   \n",
       "1               ТАСС  2018-03-29T14:16:00   \n",
       "2  Российская газета  2018-03-29T14:30:00   \n",
       "3     Телеканал 360°  2018-03-29T14:43:00   \n",
       "4          Интерфакс  2018-03-29T15:38:00   \n",
       "\n",
       "                                               title  \\\n",
       "0  В этом году на льготные автокредиты и лизинг б...   \n",
       "1  Медведев: около 50 тыс. машин продадут в 2018 ...   \n",
       "2  Кабмин выделит 7 миллиардов рублей на льготное...   \n",
       "3  Правительство РФ выделит порядка 7 млрд на льг...   \n",
       "4  Правительство выделит в 2018 г. около 7 млрд р...   \n",
       "\n",
       "                                             snippet  \\\n",
       "0  FINMARKET.RU - Премьер России Дмитрий Медведев...   \n",
       "1  Около 50 тыс. автомашин будет продано в текуще...   \n",
       "2  Правительство выделяет 7 миллиардов рублей на ...   \n",
       "3  Из указанной суммы около семи миллиардов напра...   \n",
       "4  Правительство РФ выделит в 2018 году около 7 м...   \n",
       "\n",
       "                                                text  \n",
       "0  В этом году на льготные автокредиты и лизинг б...  \n",
       "1  Около 50 тыс. автомашин будет продано в текуще...  \n",
       "2  Названы ставки по ипотеке и автокредитам в 201...  \n",
       "3  Правительством России предусмотрено свыше 12 м...  \n",
       "4  Правительство РФ выделит в 2018 году около 7 м...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = pd.read_csv('../data/interim/articles.csv')\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коррекция пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заменяем \\xad на пробел\n",
    "cleaner = lambda x: re.sub('\\xad', ' ', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#делаем все дифисы одинаковыми\n",
    "cleaner = lambda x: re.sub('[—–]', '-', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаляем кавычки\n",
    "cleaner = lambda x: re.sub('[«»\"”“\\'’„`‘\\*]', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вставляем пробелы вокруг слешей, если их не было\n",
    "\n",
    "cleaner = lambda x: re.sub(' *\\/ *', ' / ', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub(' *\\\\\\ *', ' \\ ', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub(' *\\| *', ' | ', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "#вставляем пробелы вокруг многоточия, если их не было\n",
    "\n",
    "cleaner = lambda x: re.sub(' *… *', ' … ', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаление скобок\n",
    "\n",
    "cleaner = lambda x: re.sub('\\{[^\\{\\}]*\\}', '', x)\n",
    "\n",
    "for _ in range(5):\n",
    "\n",
    "    articles.title = articles.title.apply(cleaner)\n",
    "    articles.text = articles.text.apply(cleaner)\n",
    "    \n",
    "cleaner = lambda x: re.sub('\\[[^\\[\\]]*\\]', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub('\\]', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub('\\([^\\(\\)]*\\)', '', x)\n",
    "\n",
    "for _ in range(2):\n",
    "    \n",
    "    articles.title = articles.title.apply(cleaner)\n",
    "    articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub('\\(', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub('\\)', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)\n",
    "\n",
    "cleaner = lambda x: re.sub('\\<[^\\<\\>]*\\>', '', x)\n",
    "\n",
    "articles.title = articles.title.apply(cleaner)\n",
    "articles.text = articles.text.apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11127/11127 [05:06<00:00, 38.12it/s]\n",
      "100%|██████████| 11127/11127 [07:27<00:00, 24.85it/s]\n"
     ]
    }
   ],
   "source": [
    "#Исправление опечаток\n",
    "\n",
    "speller = YandexSpeller()\n",
    "\n",
    "changes = lambda x: {change['word']: change['s'][0] for change in speller.spell(x) if change['s']}\n",
    "speller_func = lambda x: reduce(lambda x, y: x.replace(y[0], y[1]), [x]+list(changes(x).items()))\n",
    "\n",
    "articles.title = articles.title.progress_apply(speller_func)\n",
    "articles.text = articles.text.progress_apply(speller_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка новостного корпуса\n",
    "\n",
    "Предобработка будет включать следующие этапы:\n",
    "\n",
    "* разбиение текста на предложения\n",
    "* разбиение предложений на токены\n",
    "* определение морфологии\n",
    "* построение синтаксического дерева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение на предложения\n",
    "\n",
    "Используем nltk.tokenize.sent_tokenize и модель для русского языкак https://github.com/Mottl/ru_punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11127/11127 [00:00<00:00, 41983.60it/s]\n",
      "100%|██████████| 11127/11127 [00:02<00:00, 3878.50it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_tokenizer = lambda text: sent_tokenize(text, language='russian')\n",
    "\n",
    "articles['title_sents'] = articles.title.progress_apply(sent_tokenizer)\n",
    "articles['text_sents'] = articles.text.progress_apply(sent_tokenizer)\n",
    "\n",
    "articles['title_preproc'] = articles.title_sents\n",
    "articles['text_preproc'] = articles.text_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбиение на токены\n",
    "\n",
    "Используем nltk.tokenize.toktok.ToktokTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11127/11127 [00:00<00:00, 34334.49it/s]\n",
      "100%|██████████| 11127/11127 [00:04<00:00, 2581.21it/s]\n"
     ]
    }
   ],
   "source": [
    "toktok = ToktokTokenizer()\n",
    "word_tokenizer = lambda text: [toktok.tokenize(sent) for sent in text]\n",
    "\n",
    "articles.title_preproc = articles.title_preproc.progress_apply(word_tokenizer)\n",
    "articles.text_preproc = articles.text_preproc.progress_apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Морфологический анализ\n",
    "\n",
    "Хотим воспользоваться RNNMorph, но сталкиваемся с **проблемой**: слова написанные латинскими буквами воспринемаются, как пунктуация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<normal_form=новый; word=Новый; pos=ADJ; tag=Case=Nom|Degree=Pos|Gender=Masc|Number=Sing; score=0.9997>,\n",
       "  <normal_form=кроссовер; word=кроссовер; pos=NOUN; tag=Case=Nom|Gender=Masc|Number=Sing; score=0.9999>,\n",
       "  <normal_form=hyundai; word=Hyundai; pos=PUNCT; tag=_; score=1.0000>,\n",
       "  <normal_form=tucson; word=Tucson; pos=PUNCT; tag=_; score=1.0000>,\n",
       "  <normal_form=2019; word=2019; pos=NUM; tag=NumForm=Digit; score=1.0000>,\n",
       "  <normal_form=представленный; word=представлен; pos=ADJ; tag=Degree=Pos|Gender=Masc|Number=Sing|Variant=Short; score=0.9988>,\n",
       "  <normal_form=в; word=в; pos=ADP; tag=_; score=1.0000>,\n",
       "  <normal_form=нью-йорк; word=Нью-Йорке; pos=NOUN; tag=Case=Loc|Gender=Masc|Number=Sing; score=0.9987>]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnnmorph = RNNMorphPredictor()\n",
    "morph_predictor = rnnmorph.predict_sentences\n",
    "\n",
    "#Например Hyundai Tucson воспринемается как пунктуация\n",
    "morph_predictor(articles.loc[9].title_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что бы решить данную проблему, запишим все слова используя кирилические символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<normal_form=новый; word=Новый; pos=ADJ; tag=Case=Nom|Degree=Pos|Gender=Masc|Number=Sing; score=0.9999>,\n",
       "  <normal_form=кроссовер; word=кроссовер; pos=NOUN; tag=Case=Nom|Gender=Masc|Number=Sing; score=1.0000>,\n",
       "  <normal_form=хыундая; word=Хыундаи; pos=NOUN; tag=Case=Gen|Gender=Fem|Number=Sing; score=0.9992>,\n",
       "  <normal_form=туцсон; word=Туцсон; pos=NOUN; tag=Case=Nom|Gender=Masc|Number=Sing; score=0.9978>,\n",
       "  <normal_form=2019; word=2019; pos=NUM; tag=NumForm=Digit; score=1.0000>,\n",
       "  <normal_form=представленный; word=представлен; pos=ADJ; tag=Degree=Pos|Gender=Masc|Number=Sing|Variant=Short; score=0.9998>,\n",
       "  <normal_form=в; word=в; pos=ADP; tag=_; score=1.0000>,\n",
       "  <normal_form=нью-йорк; word=Нью-Йорке; pos=NOUN; tag=Case=Loc|Gender=Masc|Number=Sing; score=0.9985>]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_title_translit = []\n",
    "articles_text_translit = []\n",
    "\n",
    "for article_index, article in articles.iterrows():\n",
    "    \n",
    "    for sent_index, sent in enumerate(article.title_preproc):\n",
    "        for word_index, word in enumerate(sent):\n",
    "            \n",
    "            if re.match(r'[a-zA-Z]+', word):\n",
    "                articles_title_translit.append((article_index, sent_index, word_index, word))\n",
    "                article.title_preproc[sent_index][word_index] = translit(word, 'ru')\n",
    "                \n",
    "    for sent_index, sent in enumerate(article.text_preproc):\n",
    "        for word_index, word in enumerate(sent):\n",
    "            \n",
    "            if re.match(r'[a-zA-Z]+', word):\n",
    "                articles_text_translit.append((article_index, sent_index, word_index, word))\n",
    "                article.text_preproc[sent_index][word_index] = translit(word, 'ru')\n",
    "\n",
    "morph_predictor(articles.loc[9].title_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11127/11127 [01:32<00:00, 120.69it/s]\n",
      "100%|██████████| 11127/11127 [21:58<00:00,  8.44it/s]\n"
     ]
    }
   ],
   "source": [
    "articles.title_preproc = articles.title_preproc.progress_apply(morph_predictor)\n",
    "articles.text_preproc = articles.text_preproc.progress_apply(morph_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<normal_form=новый; word=Новый; pos=ADJ; tag=Case=Nom|Degree=Pos|Gender=Masc|Number=Sing; score=0.9999>,\n",
       "  <normal_form=кроссовер; word=кроссовер; pos=NOUN; tag=Case=Nom|Gender=Masc|Number=Sing; score=1.0000>,\n",
       "  <normal_form=хыундая; word=Hyundai; pos=NOUN; tag=Case=Gen|Gender=Fem|Number=Sing; score=0.9992>,\n",
       "  <normal_form=туцсон; word=Tucson; pos=NOUN; tag=Case=Nom|Gender=Masc|Number=Sing; score=0.9978>,\n",
       "  <normal_form=2019; word=2019; pos=NUM; tag=NumForm=Digit; score=1.0000>,\n",
       "  <normal_form=представленный; word=представлен; pos=ADJ; tag=Degree=Pos|Gender=Masc|Number=Sing|Variant=Short; score=0.9998>,\n",
       "  <normal_form=в; word=в; pos=ADP; tag=_; score=1.0000>,\n",
       "  <normal_form=нью-йорк; word=Нью-Йорке; pos=NOUN; tag=Case=Loc|Gender=Masc|Number=Sing; score=0.9985>]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for article_index, sent_index, word_index, word in articles_title_translit:\n",
    "    articles.loc[article_index].title_preproc[sent_index][word_index].word = word\n",
    "    \n",
    "for article_index, sent_index, word_index, word in articles_text_translit:\n",
    "    articles.loc[article_index].text_preproc[sent_index][word_index].word = word\n",
    "    \n",
    "articles.loc[9].title_preproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent_id = 1\n",
      "# text = Новый кроссовер Hyundai Tucson 2019 представлен в Нью-Йорке\n",
      "1\tНовый\tновый\tADJ\t_\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\t_\t_\t_\t_\n",
      "2\tкроссовер\tкроссовер\tNOUN\t_\tCase=Nom|Gender=Masc|Number=Sing\t_\t_\t_\t_\n",
      "3\tHyundai\tхыундая\tNOUN\t_\tCase=Gen|Gender=Fem|Number=Sing\t_\t_\t_\t_\n",
      "4\tTucson\tтуцсон\tNOUN\t_\tCase=Nom|Gender=Masc|Number=Sing\t_\t_\t_\t_\n",
      "5\t2019\t2019\tNUM\t_\tNumForm=Digit\t_\t_\t_\t_\n",
      "6\tпредставлен\tпредставленный\tADJ\t_\tDegree=Pos|Gender=Masc|Number=Sing|Variant=Short\t_\t_\t_\t_\n",
      "7\tв\tв\tADP\t_\t_\t_\t_\t_\t_\n",
      "8\tНью-Йорке\tнью-йорк\tNOUN\t_\tCase=Loc|Gender=Masc|Number=Sing\t_\t_\t_\tSpaceAfter=No\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "articles.title_preproc = articles[['title_sents', 'title_preproc']].apply(lambda x: zip(*x), axis=1)\n",
    "articles.title_preproc = articles.title_preproc.apply(rnnmorph_encoder).apply(conllu_decoder)\n",
    "articles = articles.drop(columns=['title_sents'])\n",
    "\n",
    "articles.text_preproc = articles[['text_sents', 'text_preproc']].apply(lambda x: zip(*x), axis=1)\n",
    "articles.text_preproc = articles.text_preproc.apply(rnnmorph_encoder).apply(conllu_decoder)\n",
    "articles = articles.drop(columns=['text_sents'])\n",
    "\n",
    "print(articles.loc[9].title_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Построение синтаксического дерева для каждого предложения\n",
    "\n",
    "Используем синтаксический парсер UDPipe, который был обучен на корпусе SynTagRus на морфологии RNNMorph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11127/11127 [00:12<00:00, 859.88it/s]\n",
      "100%|██████████| 11127/11127 [06:31<00:00, 28.39it/s]\n"
     ]
    }
   ],
   "source": [
    "parser_model = Model.load('../models/parser_model.udpipe')\n",
    "parser_pipeline = Pipeline(parser_model, 'conllu', Pipeline.NONE, Pipeline.DEFAULT, 'conllu')\n",
    "syntax_parser = lambda x: parser_pipeline.process(x, ProcessingError())\n",
    "\n",
    "articles.title_preproc = articles.title_preproc.progress_apply(syntax_parser)\n",
    "articles.text_preproc = articles.text_preproc.progress_apply(syntax_parser)\n",
    "\n",
    "articles.to_csv('../data/interim/articles_preproc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sent_id = 1\n",
      "# text = Новый кроссовер Hyundai Tucson 2019 представлен в Нью-Йорке\n",
      "1\tНовый\tновый\tADJ\t_\tCase=Nom|Degree=Pos|Gender=Masc|Number=Sing\t2\tamod\t_\t_\n",
      "2\tкроссовер\tкроссовер\tNOUN\t_\tCase=Nom|Gender=Masc|Number=Sing\t6\tnsubj:pass\t_\t_\n",
      "3\tHyundai\tхыундая\tNOUN\t_\tCase=Gen|Gender=Fem|Number=Sing\t2\tnmod\t_\t_\n",
      "4\tTucson\tтуцсон\tNOUN\t_\tCase=Nom|Gender=Masc|Number=Sing\t2\tappos\t_\t_\n",
      "5\t2019\t2019\tNUM\t_\tNumForm=Digit\t4\tnummod\t_\t_\n",
      "6\tпредставлен\tпредставленный\tADJ\t_\tDegree=Pos|Gender=Masc|Number=Sing|Variant=Short\t0\troot\t_\t_\n",
      "7\tв\tв\tADP\t_\t_\t8\tcase\t_\t_\n",
      "8\tНью-Йорке\tнью-йорк\tNOUN\t_\tCase=Loc|Gender=Masc|Number=Sing\t6\tobl\t_\tSpaceAfter=No\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(articles.loc[9].title_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В работе использовалась статья https://habr.com/company/sberbank/blog/418701/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
