{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "articles = pd.read_csv('../data/interim/articles_preproc.csv')\n",
    "decoder = CoNLLUFormatDecoder()\n",
    "\n",
    "articles.preproc_title = decoder.transform(articles.preproc_title)\n",
    "articles.preproc_text = decoder.transform(articles.preproc_text)\n",
    "\n",
    "phr_extracter = PhraseExtracter(min_count=3).fit(articles.preproc_title.tolist()+articles.preproc_text.tolist())\n",
    "\n",
    "phrases_title = phr_extracter.transform(articles.preproc_title)\n",
    "phrases_text = phr_extracter.transform(articles.preproc_text)\n",
    "\n",
    "_, _, title_sigs = zip(*chain(*chain(*phrases_title)))\n",
    "_, _, text_sigs = zip(*chain(*chain(*phrases_text)))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "axs[0].hist(title_sigs, bins=500)\n",
    "axs[0].set_ylabel('Number of phrases in titles')\n",
    "\n",
    "axs[1].hist(text_sigs, bins=500)\n",
    "axs[1].set_ylabel('Number of phrases in texts')\n",
    "axs[1].set_xlabel('Sig')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = []\n",
    "\n",
    "for phrase_title, phrase_text, (article_id, article_title, article_text) in \\\n",
    "zip(phrases_title, phrases_text, articles[['id', 'preproc_title', 'preproc_text']].values):\n",
    "    \n",
    "    for phrase_title_sent, article_title_sent in zip(phrase_title, article_title):\n",
    "        \n",
    "        tokens = article_title_sent.tokens\n",
    "        for begin_index, end_index, sig in phrase_title_sent:\n",
    "            phrase = tokens[begin_index:end_index]\n",
    "            \n",
    "            spaces = [token.space for token in phrase]\n",
    "            forms = [token.form for token in phrase]\n",
    "            lemmas = [token.lemma for token in phrase]\n",
    "            \n",
    "            phrase_form = ''.join([form + (' ' if space else '') for form, space in zip(forms, spaces)]).strip()\n",
    "            phrase_lemma = ''.join([lemma + (' ' if space else '') for lemma, space in zip(lemmas, spaces)]).strip()\n",
    "            \n",
    "            phrases.append((article_id, 'title', article_title_sent.sent_id, begin_index, end_index, phrase_form, phrase_lemma, sig))\n",
    "            \n",
    "    for phrase_text_sent, article_text_sent in zip(phrase_text, article_text):\n",
    "        \n",
    "        tokens = article_text_sent.tokens\n",
    "        for begin_index, end_index, sig in phrase_text_sent:\n",
    "            phrase = tokens[begin_index:end_index]\n",
    "            \n",
    "            spaces = [token.space for token in phrase]\n",
    "            forms = [token.form for token in phrase]\n",
    "            lemmas = [token.lemma for token in phrase]\n",
    "            \n",
    "            phrase_form = ''.join([form + (' ' if space else '') for form, space in zip(forms, spaces)]).strip()\n",
    "            phrase_lemma = ''.join([lemma + (' ' if space else '') for lemma, space in zip(lemmas, spaces)]).strip()\n",
    "            \n",
    "            phrases.append((article_id, 'text', article_text_sent.sent_id, begin_index, end_index, phrase_form, phrase_lemma, sig))\n",
    "            \n",
    "phrases = pd.DataFrame(phrases, columns=['article_id', 'article_part', 'sent_id', 'begin_index', 'end_index', 'phrase_form', 'phrase_lemma', 'sig'])\n",
    "phrases.to_csv('../data/interim/phrases.csv', index=False)\n",
    "\n",
    "form_encoder = LabelEncoder().fit(phrases.phrase_form)\n",
    "phrases.phrase_form = form_encoder.transform(phrases.phrase_form)\n",
    "\n",
    "phrases_form = pd.DataFrame([(form_id, form) for form_id, form in enumerate(form_encoder.classes_)], columns=['form_id', 'form'])\n",
    "phrases_form.to_csv('../data/interim/phrases_form.csv', index=False)\n",
    "\n",
    "lemma_encoder = LabelEncoder().fit(phrases.phrase_lemma)\n",
    "phrases.phrase_lemma = lemma_encoder.transform(phrases.phrase_lemma)\n",
    "\n",
    "phrases_lemma = pd.DataFrame([(lemma_id, lemma) for lemma_id, lemma in enumerate(lemma_encoder.classes_)], columns=['lemma_id', 'lemma'])\n",
    "phrases_lemma_sig = pd.DataFrame([(lemma_id, group.sig.mean()) for lemma_id, group in phrases.groupby('phrase_lemma')], columns=['lemma_id', 'sig'])\n",
    "phrases_lemma = pd.merge(phrases_lemma, phrases_lemma_sig, on='lemma_id')\n",
    "\n",
    "phrases_lemma.to_csv('../data/interim/phrases_lemma.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
